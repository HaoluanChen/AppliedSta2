---
title: "Assignment1"
author: "Haoluan Chen"
format: pdf
editor: visual
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(readxl)
library(tidyverse)
library(readr)
library(skimr) # EDA
library(MASS)
library(reshape2)
library(gridExtra)
library(knitr)
```

# Q1

## a)

Assume $E[\theta]=1$ and $Var(\theta) = \sigma^2$

By the Law of total expectation and $Y|\theta$ \~ Poisson($\mu\theta$):

$E(Y) = E[E(Y|\theta)] = E[\mu\theta] = \mu E[\theta] = \mu$

By the Law of total variance and $Y|\theta$ \~ Poisson($\mu\theta$):

$Var(Y|\theta) = E[Var(Y|\theta)] + Var[E(Y|\theta)] = E[\mu\theta] + Var(\mu\theta) = \mu+\mu^2\sigma^2 = \mu(1+\mu\sigma^2)$

## b)

Assume $\theta$ \~ $Gamma(\alpha, \beta)0$

$$p(y) = \int_{}^{}p(y|\theta)p(\theta)d\theta $$ $$=\int_{}^{} \frac{(\mu\theta)^ye^{-\mu\theta}}{y!}\frac{\theta^{\alpha-1}e^{-\theta/\beta}}{\beta^\alpha\Gamma(\alpha)}d\theta $$ $$ = \frac{\mu^y}{\beta^\alpha y! \Gamma(\alpha)}\int_{}^{} \theta^{y+\theta-1}e^{-\mu\theta-\theta/\beta} d\theta $$ $$= \frac{\mu^y}{\beta^\alpha y! \Gamma(\alpha)}\int_{}^{}e^{-\theta(\mu+1/\beta)}\theta^{y+\alpha-1}$$ $$= \frac{\mu^y}{\beta^\alpha y! \Gamma(\alpha)} \frac{\Gamma(y+\alpha)}{(\mu+1/\beta)^{y+\alpha}}$$ $$= \frac{\Gamma(y+\alpha)}{\Gamma(\alpha)\Gamma(y+1)}\frac{\mu^y}{\beta^\alpha}(\frac{\mu\beta+1}{\beta})^{-y-\alpha}$$

$$= \frac{\Gamma(y+\alpha)}{\Gamma(\alpha)\Gamma(y+1)}\frac{\mu^y}{\beta^\alpha}\frac{\beta^{y+\alpha}}{(\mu\beta+1)^{y+\alpha}}$$

$$= \frac{\Gamma(y+\alpha)}{\Gamma(\alpha)\Gamma(y+1)}(\frac{\mu\beta}{\mu\beta+1})^y(\frac{1}{\mu\beta+1})^\alpha \sim NB(\alpha, \frac{\mu\beta}{\mu\beta+1})$$

## c)

Since

$E(Y) = \mu = \frac{\alpha(1- \frac{\mu\beta}{\mu\beta+1})}{\frac{\mu\beta}{\mu\beta+1}} = \alpha\mu\beta => \alpha\beta = 1$

$Var(Y) = \mu(1+\mu\sigma^2) = \frac{\alpha(1- \frac{\mu\beta}{\mu\beta+1})}{(\frac{\mu\beta}{\mu\beta+1})^2} = \alpha\mu\beta+\alpha\mu^2\beta^2 => \alpha\beta^2= \sigma^2$

Then

$\alpha = 1/\sigma^2, \beta = \sigma^2$


# Q2

```{r echo= FALSE}
q2 <- read_excel("data/q2.xlsx")
```

## a)

```{r echo= FALSE, fig.height=10}
q2a1 <- q2 %>% ggplot(aes(x=MasFem, y=alldeaths)) + geom_point() + 
  xlab("Femininity(MFI)") + ylab("Death")
q2a2 <- q2 %>% ggplot(aes(x=MinPressure_before, y=alldeaths)) + geom_point() +
    xlab(" minimum pressure") + ylab("Death")
q2a3 <- q2 %>% ggplot(aes(x=NDAM, y=alldeaths)) + geom_point()+
  xlab(" Normalized Damage") + ylab("Death")
grid.arrange(q2a1, q2a2,q2a3, ncol=1)
```

From the death by femininity scatter plot, it looks like there is two cluster. A group centered around femininity value of 2 and a group centered around femininity value of 8.5. Higher femininity value has higher variability on the number of deaths. One extreme value of over 200 deaths. For minimum pressure, there is a slightly increasing trend as the minimum pressure goes below 950. Lastly, we see an increasing in deaths as normalized damage increase, the variation also increase. 


## b)

Fitting Poisson model(Estimates are exponentiated) : 
```{r }
model1 <- glm(alldeaths~MasFem, family = poisson, data = q2)
est <- data.frame(summary(model1)$coefficients) %>% 
  mutate(Estimate = exp(Estimate))
kable(round(est, 4))
```


The poisson model suggested that as the MFI increase by one unit, the death count increase by a factor of 1.0767



Checking for overdispersion:
```{r}
standard_res <- rstandard(model1)
plot(fitted(model1), standard_res)
```

```{r}
n = 92
k = 2
sum(standard_res^2)/(n-k)
```

```{r}
1-pchisq(sum(standard_res^2), n-k)
```
There is an overdispersion!


Fitting quasi-poisson model(Estimates are exponentiated):

```{r echo= FALSE}
model2 <- glm(alldeaths~MasFem, family = quasipoisson, data = q2)
est2 <- data.frame(summary(model2)$coefficients) %>% 
  mutate(Estimate = exp(Estimate))
kable(round(est2, 4))
```

Assuming the significant level to be 0.05. The quasi-poisson suggest that the MFI does not affect on the death count.

## c)

Model 4(Estimates are exponentiated): 

```{r echo= FALSE}
cmodel<-glm.nb(alldeaths ~ ZMasFem*ZMinPressure_A + ZMasFem*ZNDAM , data=q2)
kable(round(summary(cmodel)$coefficients, 4))
```

```{r}
exp(0.1723)
```

Assuming a hurricane with median pressure and damage ratings, the estimated effect of one unit increase in MFI on death count is 18.8%

## d)

```{r}
d <- q2%>% filter(Name == "Sandy")
sandy <- d[12:14]
predict(cmodel, sandy, type="response")
```
The predicted death count for Sandy is 20807. However, the actual death count is only 159. The predicted death count is so high because Sandy has highest damage. 

## e)

weakness: 

1. Only 9 independent coder were included in determine the MFI, which may be biased. More coder can be included.

2. P-value of the models were not include in the table. 

strength: 

1. Recognizing the confounding variable: effect of gendered names on protective action, not simply conclude that Feminine-named hurricanes cause significantly more deaths. 

2. Many experiment were carried out to test difference aspect about the perceived risk of the hurricanes, predicted intensity and evacuation intention. This wide range of experiment helps convince reader that gendered hurricanes names will affect how people feel and act.

3. Data set are available for reproducible 

## f)

I think I'm convinced by the experiments result that people perceive male named hurricanes are slightly more risk/intensity and will more likely to follow evacuation plan. However, I'm not convinced that the name of the hurricanes have impact on the total death. Firstly, both the quasi-poisson and negative binomial model suggested that there is not effect of the MFI on the total death. Furthermore, there are about 2/3 of the hurricanes with feminine names and 1/3 of the hurricanes with masculine names, and it looks like there are four extreme values for hurricanes with more feminine names. It may be due to chance that these sever hurricane got a feminine name. Lastly, I noticed that there are duplicates in the names, and most of the time, the later hurricane caused more damage and deaths(Bob, Bonnie, Charley, Danny, Floyd, Irene), maybe calling two hurricanes same is not a good idea? People may let their guard down. 

```{r}
f1 <- q2 %>% ggplot(aes(MasFem))+ geom_histogram() + xlab("Femininity(MFI)")
f2 <- q2 %>% ggplot(aes(x=MasFem, y=alldeaths)) + geom_point() + 
  xlab("Femininity(MFI)") + ylab("Death")
grid.arrange(f1, f2, ncol=2)
```



# Q3

Loading and combining two datasets
```{r echo= FALSE}
q3 <- read_csv("data/q3.csv")
q3 <- dplyr::select(q3, FIPS, starts_with("Series_Complete"), )
acs <- read_csv("data/acs.csv")
acs <- acs %>% pivot_wider(names_from = variable, values_from=value)
acs <- acs %>% rename(FIPS = fips)
combined <- inner_join(q3, acs, by='FIPS')
```


## a)

There are very few data points that are missing. Most of the variable has complete rate of 99%. I removed the missing assuming they are missing completely at random. 

```{r}
combined <- na.omit(combined)
```

Check distribution of the count

```{r echo= FALSE}
combined %>% ggplot(aes(Series_Complete_18PlusPop_Pct))+ geom_histogram()
```

The distribution looks pretty normal, but with a small mode at 95%. 

```{r echo= FALSE,fig.width=15, fig.height=20}
q3a1 <- combined %>% ggplot(aes(x=median_income, y=Series_Complete_18PlusPop_Pct)) + geom_point()
q3a2 <- combined %>% ggplot(aes(x=prop_white, y=Series_Complete_18PlusPop_Pct)) + geom_point()
q3a3 <- combined %>% ggplot(aes(x=prop_health_insurance, y=Series_Complete_18PlusPop_Pct)) + geom_point()
q3a4 <- combined %>% ggplot(aes(x=median_rent, y=Series_Complete_18PlusPop_Pct)) + geom_point()
q3a5 <- combined %>% ggplot(aes(x=prop_unemployed, y=Series_Complete_18PlusPop_Pct)) + geom_point()
grid.arrange(q3a1, q3a2,q3a3, q3a4,q3a5, ncol=2)
```

There is some increasing trend for some of the variables, such as median income and median rent. And maybe a slight decreasing in vaccination rate as the population white increase. There is no obvious trend for health insurance or unemployed. 

Correlation heat map for acs data.

```{r  echo= FALSE, fig.width=12, fig.height=12}
correlationacs <- dplyr::select(acs, -FIPS, -county_name)
correlationacs<- na.omit(correlationacs)
# creating correlation matrix
corr_mat <- round(cor(correlationacs),2)
# reduce the size of correlation matrix
melted_corr_mat <- melt(corr_mat)
# head(melted_corr_mat)
# plotting the correlation heatmap
ggplot(data = melted_corr_mat, aes(x=Var1, y=Var2,
                                   fill=value)) +
  geom_tile(color = "black") + 
  scale_fill_gradient(low = "white", high = "red") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+
  geom_text(aes(label = value), color = "black", size = 4)
```

## b)

I chose to use binomial model, since the proportion is a probability between 0 and 1. And I assume the outcome follows a binomial distribution, one person is completed the vaccine is consider as a success, each county is a binomial sample. 

I chose covariates that I am interested in(proportion of white people, proportion of health insurance, proportion of foreign born) and the covariates that has a decreasing/increasing impact on vaccine completion rate based on my EDA(median income). Also, I avoided including multiple covariates that are highly correlated(median income, median rent, bachelor above).

In term of choosing the candidate model, I fitted a large model and a small model. The larger model includes the covariates that I'm interested in. And the covariates in small model are selected by backward elimination, which includes covariates that are significant in the large model. 



```{r}
modeldata3b <- combined %>%
  mutate(Series_Complete_18PlusPop_Pct_model = Series_Complete_18PlusPop_Pct/100)
model3b1 <- glm(Series_Complete_18PlusPop_Pct_model ~ 
                  prop_white + prop_foreign_born+ 
                 median_income +prop_unemployed + prop_nilf + 
                 prop_health_insurance + prop_low_ratio_ip, 
               family = binomial, data = modeldata3b)
```

```{r}
kable(round(summary(model3b1)$coefficients, 4))
```

```{r}
model3b2 <- glm(Series_Complete_18PlusPop_Pct_model ~ 
                  prop_white + prop_foreign_born+ 
                 median_income +prop_unemployed + 
                 prop_health_insurance, 
               family = binomial, data = modeldata3b)

```

```{r}
summary(model3b2)
kable(round(summary(model3b2)$coefficients, 4))
```

```{r}
est <- data.frame(summary(model3b2)$coefficients) %>% 
  mutate(Estimate = exp(Estimate))
kable(round(est, 4))
```


Assuming 0.05 significance level. We see that everything in the small model are significant expect for prop_unemployed. Among the significant covariates, the median income has the odds of one, this means that the median income does not have an impact on the vaccination rate. The proportion of foreign born and health insurance have positive impact on the vaccine rate, with odd ratio of 11.46, 328.31 and 25.30 compared to our baseline respectively. Additionally, the proportion of white people does have an negative effect on the vaccination rate, about 50% reduction in odds ratio compared to the basedline.  


## c)

```{r }
Ada <- modeldata3b %>% filter(county_name == "Ada County, Idaho") 
Ada <- dplyr::select(Ada, prop_white, prop_foreign_born, 
                 median_income,prop_unemployed, prop_nilf, 
                 prop_health_insurance, prop_low_ratio_ip, total_pop_18plus)
```

```{r}
dplyr::select(modeldata3b, county_name, Series_Complete_18PlusPop_Pct) %>% 
  filter(county_name == "Ada County, Idaho")

predict(model3b2, Ada, type = "response")
```

The prediction is about 10% off. I guess it is pretty good considering the variability in the data

## d)


In summary, our model suggest that the proportion of foreign born and health insurance have positive impact on the vaccine rate. Income related estimates does not seen to have an impact. Interestingly, the proportion of white people have an negative effect on the vaccination rate. However, our model is only based on current available data, there may be some confounding variable that are not included in our analysis. For example, maybe the county with higher proportion of white people are mostly elders, which may be more reluctant or worried about the side affect of the vaccine. Therefore, age may be of interest to investigate in future.


## e)

For first option, I think it has the second highest granularity of information, since it is combining the count of 18+ fully vaccinated in county level into state level. The Second option has least granularity of information since it is averaging the county results. And the last option is not only using the information in county level(mode detailed level), but also includes county as a covariate. 

In my opinion, the the third option is not appropriate in most of the case because it contains way too many covariates, we will not be able to extract useful information from it. First and second option depends on weather or not you are interested in the total count or average of the county level. Note that the average will suffer from problem of outlier 
